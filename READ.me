# Parser

This is a parser for crawled webpages. It was used on 3rd Information Retrieval Assignment, from UFMG.

## Requirements

You must have the [Chilkat](https://www.chilkatsoft.com/downloads.asp), [Gumbo-Parser](https://github.com/google/gumbo-parser) and pthread libraries installed.

## Usage

The parser will start the execution by parsing the HTML pages inside collection repository.

For changing the path for your collection repository or the size of the collection or the path for output, you can do it on parser.h.


You can compile the parser by doing make:
```
make
```
If something goes wrong with make, check the version of Chilkat installed on your machine (MakeFile by default runs with version 9.5.0 of Chilkat. For changes, do it on -lchilkat-9.5.0).

Other problems that may occur are the include and library paths, check if they are correct.


If everything occours fine, you can run the program by executing:
```
./parser
```

## Results
Will be printed:

Mini-Collection Number of Pages
Mini-Collection Size (in \texttt{Kbytes})
Size of the vocabulary (number of distinct terms)
Total Terms Count
Average Size of each inverted list
Inverted Index Size (in \texttt{Kbytes})
Average number of documents for each term
Average time for processing each page
Total time
THE 25 MOST FREQUENT TERMS AND NUMBER OF OCCURRENCES 



Anything you can refer an email to: gabpaivapereira@gmail.com

Author: Gabriel Felipe Paiva Pereira
